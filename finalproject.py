# -*- coding: utf-8 -*-
"""Real FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kX20zf6_RtKiYZ83pD0dB6kL_mDyw86M
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder

data = pd.read_csv('/content/drive/MyDrive/crop_yield.csv')

data.head()

data.info()

data.columns.tolist()

# Data preparation & feature extraction process

# Checking for missing values
print(data.isnull().sum())

# We want to predict the market trends for a specific crop in India throughout the year

data.columns.tolist()

# Count the distinct number of crops in the dataset
number_of_crops = data['Crop'].nunique()
number_of_crops

# Print the distinct number of crops in the dataset
distinct_crops = data['Crop'].unique()
print(distinct_crops)

# Count the distinct number of seasons in the dataset
number_of_seasons = data['Season'].nunique()
number_of_seasons

# Print the distinct number of seasons in the dataset
distinct_seasons = data['Season'].unique()
print(distinct_seasons)

# Count the distinct number of states in the dataset
number_of_states = data['State'].nunique()
number_of_states

# Print the distinct number of states in the dataset
distinct_states = data['State'].unique()
print(distinct_states)

# Separating the categorical and quantitative variables
numeric_data = data.select_dtypes(include = np.number)
non_numericdata = data.select_dtypes(include = ['object'])

numeric_data

non_numericdata

# Scaling
scaler = StandardScaler()
scaled_numeric_data = scaler.fit_transform(numeric_data)

# Convert the scaled data back to a DataFrame
scaled_numeric_data_df = pd.DataFrame(scaled_numeric_data, columns=numeric_data.columns)
scaled_numeric_data_df

# Encoding the categorical features using label encoding
encoded_data = pd.get_dummies(data, columns=['Crop', 'Season', 'State'])

# Encoding the categorical features using Label Encoding
label_encoders = {}

for i in non_numericdata.columns:
    # Convert the columns to strings before encoding
    data[i] = data[i].astype(str)  # Ensure all values are strings
    label_encoders[i] = LabelEncoder()
    data[i] = label_encoders[i].fit_transform(data[i])

encoded_data

non_numericdata_df = pd.DataFrame(non_numericdata, columns=non_numericdata.columns)

encoded_non_numeric_data = data[non_numericdata_df.columns]

# Reset indexes to ensure alignment
scaled_numeric_data_df.reset_index(drop=True, inplace=True)
encoded_non_numeric_data.reset_index(drop=True, inplace=True)

# Creating a dataframe that contains both the numeric and non numeric variables
new_data = pd.concat([scaled_numeric_data_df, encoded_non_numeric_data], axis=1)
new_data.columns.tolist()

new_data

# Calculating the correlation matrix for the numerical features
correlation_matrix = new_data.corr()

# Displaying the correlation matrix
correlation_matrix

# We want to check which features are highly correlated with yield

# Extract correlations with Production
yield_corr = correlation_matrix['Yield']

# Sort the correlations in descending order
sorted_yield_corr = yield_corr.sort_values(ascending=False)

# Print correlations with Production
print("\nCorrelations with Yield:")
print(sorted_yield_corr)

import seaborn as sns
import matplotlib.pyplot as plt

# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Histogram of numerical features
data.hist(bins=30, figsize=(20, 15))
plt.show()

# Feature Selection Using Random Forest
# We first used Random Forest because of its ability to handle non-linear relationships and its robustness to overfitting due to averaging multiple trees.

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

# Separating the features and target variable (here 'Yield' is what we want to predict so that is the target)
X = new_data.drop(columns=['Yield'])
y = new_data['Yield']

# Splitting the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training the Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print evaluation metrics
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R-squared: {r2}")

# Extracting feature importances
feature_importances = rf_model.feature_importances_

# Creating a DataFrame for visualization
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Displaying the feature importances
print(feature_importance_df)

import matplotlib.pyplot as plt

# Plotting the feature importances
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances')
plt.gca().invert_yaxis()  # To display the highest importance at the top
plt.show()

# Finetuning
from sklearn.model_selection import GridSearchCV

# Random Forest hyperparameter grid
rf_param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['auto', 'sqrt']
}

# Grid search with a reduced number of parallel jobs
rf_grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),
                              param_grid=rf_param_grid,
                              cv=5, n_jobs=2, scoring='neg_mean_squared_error')

rf_grid_search.fit(X, y)
best_rf_model = rf_grid_search.best_estimator_
print("Best Random Forest Parameters:", rf_grid_search.best_params_)

# Get the best hyperparameters
best_params = rf_grid_search.best_params_
best_model = rf_grid_search.best_estimator_

# Print the best hyperparameters
print("Best Hyperparameters:", best_params)

# Evaluate the best model
y_pred = best_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print evaluation metrics for the best model
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R-squared: {r2}")

from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt

# Load and preprocess the data (assumed to be in a DataFrame called 'data')
data = pd.read_csv('/content/drive/MyDrive/crop_yield.csv')
data['Date'] = pd.to_datetime(data['Crop_Year'], format='%Y')
data.set_index('Date', inplace=True)
data['Yield'] = data['Yield'].astype(float)

# Assuming 'Yield' is the target variable and other columns are features
features = data.drop(columns=['Yield'])
target = data['Yield']

# Encoding categorical features (if any)
label_encoders = {}
for column in features.select_dtypes(include=['object']).columns:
    label_encoders[column] = LabelEncoder()
    features[column] = label_encoders[column].fit_transform(features[column])

# Scaling features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

# Converting the target to numpy array
target = target.values

# Function to reshape data for LSTM
def reshape_data(X, y, time_steps):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:i + time_steps])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

time_steps = 5  # Number of previous time steps to use for prediction
X_reshaped, y_reshaped = reshape_data(scaled_features, target, time_steps)

# Splitting the data into training and testing sets
train_size = int(X_reshaped.shape[0] * 0.8)
X_train, X_test = X_reshaped[:train_size], X_reshaped[train_size:]
y_train, y_test = y_reshaped[:train_size], y_reshaped[train_size:]

# Define the model creation function
def create_model(optimizer='adam', units=128, activation='relu', dropout_rate=0.0):
    model = keras.Sequential([
        keras.layers.LSTM(units, activation=activation, input_shape=(X_train.shape[1], X_train.shape[2])),
        keras.layers.Dropout(dropout_rate),
        keras.layers.Dense(64, activation=activation),
        keras.layers.Dense(1)  # Output layer for regression
    ])
    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])
    return model

# Hyperparameters to try
param_grid = {
    'optimizer': ['adam'],
    'units': [50, 100],
    'activation': ['relu'],
    'dropout_rate': [0.0, 0.2],
    'batch_size': [16, 32],
    'epochs': [50, 100]
}

# Manual Grid Search
best_mae = float('inf')
best_model = None
best_params = {}

for optimizer in param_grid['optimizer']:
    for units in param_grid['units']:
        for activation in param_grid['activation']:
            for dropout_rate in param_grid['dropout_rate']:
                for batch_size in param_grid['batch_size']:
                    for epochs in param_grid['epochs']:
                        print(f"Training with {optimizer=}, {units=}, {activation=}, {dropout_rate=}, {batch_size=}, {epochs=}")
                        model = create_model(optimizer, units, activation, dropout_rate)
                        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)
                        loss, mae = model.evaluate(X_test, y_test, verbose=0)

                        if mae < best_mae:
                            best_mae = mae
                            best_model = model
                            best_params = {
                                'optimizer': optimizer,
                                'units': units,
                                'activation': activation,
                                'dropout_rate': dropout_rate,
                                'batch_size': batch_size,
                                'epochs': epochs
                            }

# Display best model's parameters
print(f"Best MAE: {best_mae}")
print(f"Best Parameters: {best_params}")

# Save the best model
best_model.save('best_lstm_model.h5')

# Evaluate the best model
y_pred = best_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"Mean Absolute Error: {mae}")
print(f"R-squared: {r2}")

import tensorflow as tf
from tensorflow import keras

# Define the model
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(1)  # Output layer for regression
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f"Mean Absolute Error: {mae}")

# Make predictions
y_pred = model.predict(X_test)

# Calculate R-squared
r2 = r2_score(y_test, y_pred)
print(f"R-squared: {r2}")

# Plotting the training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plotting the training and validation MAE
plt.figure(figsize=(10, 6))
plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.title('Training and Validation MAE')
plt.legend()
plt.show()

# Scatter plot of predicted vs actual values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.show()

# Scaling the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Convert scaled features back to DataFrame
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# Reshape data to 3D array for time series
def reshape_data(X, y, time_steps):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X.iloc[i:(i + time_steps)].values)
        ys.append(y.iloc[i + time_steps])
    return np.array(Xs), np.array(ys)

time_steps = 5  # Number of time steps to consider
X_reshaped, y_reshaped = reshape_data(X_scaled_df, y, time_steps)

# Split the reshaped data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.2, random_state=42)

# Ensure the target is reshaped properly
y_train = y_train.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

# LSTM was also chosen for its ability to model sequential data and capture temporal dependencies.

# Define the LSTM model
model = keras.Sequential([
    keras.layers.LSTM(128, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(1)  # Output layer for regression
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f"Mean Absolute Error: {mae}")

# Make predictions
y_pred = model.predict(X_test)

# Calculate R-squared
r2 = r2_score(y_test, y_pred)
print(f"R-squared: {r2}")

# Plotting the training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plotting the training and validation MAE
plt.figure(figsize=(10, 6))
plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.title('Training and Validation MAE')
plt.legend()
plt.show()

# Scatter plot of predicted vs actual values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.show()

# XGBoost
# We used this too for its efficiency and performance in handling large datasets and its ability to capture complex patterns.
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train the XGBoost model
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
xgb_model.fit(X_train, y_train)

# Make predictions
y_pred = xgb_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"Mean Absolute Error: {mae}")
print(f"R-squared: {r2}")

# SARIMA. Since we are dealing with time series data, particularly in capturing seasonality and trends. This was suitable.
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Load the data (assuming it's already available as `data`)
data.index = pd.to_datetime(data.index)  # Ensure the index is datetime

# Verify 'Yield' column exists and contains the expected data
print(data['y'].head())

# Split data into train and test sets
train_size = int(len(data) * 0.8)
train, test = data.iloc[:train_size], data.iloc[train_size:]

# Define the SARIMA model configuration (revised for experimentation)
order = (2, 1, 2)
seasonal_order = (2, 1, 1, 12)  # Assuming annual seasonality

# Fit the SARIMA model
sarima_model = SARIMAX(train['y'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)
sarima_results = sarima_model.fit(disp=False)

# Forecast and predict
start = len(train)
end = len(train) + len(test) - 1
forecast = sarima_results.predict(start=start, end=end, dynamic=False)

# Evaluate the model
mse = mean_squared_error(test['y'], forecast)
rmse = np.sqrt(mse)
mae = mean_absolute_error(test['y'], forecast)
r2 = r2_score(test['y'], forecast)

# Print the evaluation metrics
print("SARIMA Evaluation Metrics:")
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R-squared: {r2}")

# Plot the results
plt.figure(figsize=(10, 5))
plt.plot(train.index, train['y'], label='Train')
plt.plot(test.index, test['y'], label='Test')
plt.plot(test.index, forecast, label='Forecast')
plt.title('SARIMA Model - Actual vs Forecast')
plt.xlabel('Year')
plt.ylabel('Yield')
plt.legend()
plt.grid(True)
plt.show()

# Save the rf model as a pickle file
import joblib

# Random Forest was the best model
joblib.dump(best_model, 'best_random_forest_model_new.pkl')

from google.colab import files

# Download the model file
files.download('best_random_forest_model.pkl')